{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载所有Release文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "def download_and_extract(download_url, filename, extract_dir):\n",
    "    print(\"download_url\", download_url)\n",
    "    print(\"filename\", filename)\n",
    "    print(\"extract_dir\", extract_dir)\n",
    "    # 下载zip文件\n",
    "    r = requests.get(download_url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    # 解压zip文件\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    # 删除zip文件\n",
    "    os.remove(filename)\n",
    "\n",
    "def main(username, repo_name, auth_token):\n",
    "    url = f'https://api.github.com/repos/{username}/{repo_name}/releases'\n",
    "    headers = {'Authorization': f'token {auth_token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # 解析JSON响应并获取release信息\n",
    "    releases = []\n",
    "    if response.ok:\n",
    "        json_data = response.json()\n",
    "        for release in json_data:\n",
    "            release_id = release['id']\n",
    "            name = release['name']\n",
    "            tag_name = release['tag_name']\n",
    "            if(not tag_name.startswith('movielens-1m-detail')):\n",
    "                continue\n",
    "\n",
    "            # 下载并提取zip文件中的数据文件\n",
    "            for asset in release['assets']:\n",
    "                if asset['content_type'] == 'application/zip':\n",
    "                    download_url = asset['browser_download_url']\n",
    "                    filename = asset['name']\n",
    "                    extract_dir = f'{repo_name}_extracted_{release_id}'\n",
    "                    os.makedirs(extract_dir, exist_ok=True)\n",
    "                    download_and_extract(download_url, filename, extract_dir)\n",
    "                    data_path = os.path.join(extract_dir, f'app/data')\n",
    "                    print(\"data_path\", data_path)\n",
    "                    if not os.path.exists('out'):\n",
    "                        os.makedirs('out', exist_ok=True)\n",
    "                    if os.path.exists(data_path):\n",
    "                        # 遍历data_path目录下的所有csv文件，拷贝到out目录中\n",
    "                        for root, dirs, files in os.walk(data_path):\n",
    "                            for file in files:\n",
    "                                if file.endswith('.csv') and file.startswith('output'):\n",
    "                                    src_file = os.path.join(root, file)\n",
    "                                    dest_file = f'out/{repo_name}_{tag_name}_{release_id}_outputs.csv'\n",
    "                                    shutil.copyfile(src_file, dest_file)\n",
    "                    # 删除解压后的文件夹\n",
    "                    shutil.rmtree(extract_dir)\n",
    "\n",
    "auth_token = \"\"\n",
    "with open('AUTH_TOKEN','r') as f:\n",
    "    auth_token = f.read().strip()\n",
    "main(\"includeno\", \"spider_movielens_1m\", auth_token)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并out文件夹内所有csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_folder = 'out'  # 指定文件夹名称\n",
    "csv_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "count=0\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "    dfs.append(df)\n",
    "    count=count+1\n",
    "print(count)\n",
    "\n",
    "FOLDER='data'\n",
    "if not os.path.exists(FOLDER):\n",
    "    os.makedirs(FOLDER, exist_ok=True)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df.drop_duplicates(subset=['url'], keep='last', inplace=True)\n",
    "df.to_csv(f'{FOLDER}/concat.csv', index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
